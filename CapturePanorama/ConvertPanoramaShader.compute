#pragma kernel CubeMapToEquirectangular
#pragma kernel CubeMapToEquirectangularPositiveY
#pragma kernel CubeMapToEquirectangularNegativeY

RWStructuredBuffer<uint> result;
StructuredBuffer<uint> cameraPixels;
SamplerState MyLinearClampSampler;
int equirectangularWidth;
int equirectangularHeight;
int ssaaFactor;
int cameraWidth;
int cameraHeight;
int startY;

[numthreads(32,32,1)] // Must match threadsX, threadsY in CapturePanorama.cs
void CubeMapToEquirectangular (uint3 dtid : SV_DispatchThreadID)
{
    // Must match enum UnityEngine.CubemapFace
    static const int PositiveX = 0;
    static const int NegativeX = 1;
    static const int PositiveY = 2;
    static const int NegativeY = 3;
    static const int PositiveZ = 4;
    static const int NegativeZ = 5;

	static const float pi = 3.14159265f;
	float4 totalColor = float4(0.0f, 0.0f, 0.0f, 0.0f);

	int2 pos = int2(dtid.x, dtid.y + startY);
	int2 loopStart = pos * ssaaFactor;
	int2 loopEnd = loopStart + int2(ssaaFactor, ssaaFactor);

	for (int y = loopStart.y; y < loopEnd.y; y++)
	{
		for (int x = loopStart.x; x < loopEnd.x; x++)
		{
			float xcoord = (float)x / (equirectangularWidth * ssaaFactor);
			float ycoord = (float)y / (equirectangularHeight * ssaaFactor);
			float latitude = (ycoord - 0.5f) * pi;
			float longitude = (xcoord * 2.0f - 1.0f) * pi;

			float cosLat = cos(latitude);
			float equirectRayDirectionX = cosLat * sin (longitude);
			float equirectRayDirectionY = sin (latitude);
			float equirectRayDirectionZ = cosLat * cos (longitude);

			float distance;
			float u, v;
			int cameraNum;

			distance = 1.0f / equirectRayDirectionY;
			u = equirectRayDirectionX * distance; v = equirectRayDirectionZ * distance;
			if (u * u <= 1 && v * v <= 1) {
				if (equirectRayDirectionY > 0.0f) {
					cameraNum = PositiveY;
				} else {
					u = -u;
					cameraNum = NegativeY;
				}
			}
	        else
			{
				distance = 1.0f / equirectRayDirectionX;
				u = -equirectRayDirectionZ * distance; v = equirectRayDirectionY * distance;
				if (u * u <= 1 && v * v <= 1) {
					if (equirectRayDirectionX > 0.0f) {
						v = -v;
						cameraNum = PositiveX;
					} else {
						cameraNum = NegativeX;
					}
				}
				else
				{
					distance = 1.0f / equirectRayDirectionZ;
					u = equirectRayDirectionX * distance; v = equirectRayDirectionY * distance;
					if (u * u <= 1 && v * v <= 1) {
						if (equirectRayDirectionZ > 0.0f) {
							v = -v;
							cameraNum = PositiveZ;
						} else {
							cameraNum = NegativeZ;
						}
					}
				}
			}

			u = (u + 1.0f) * 0.5f;
			v = (v + 1.0f) * 0.5f;

			// GetCameraPixelBilinear(cameraPixels, cameraNum, u, v);

			u *= cameraWidth;
			v *= cameraHeight;
			int left   = min(cameraWidth  - 1, (int)floor(u)); // Modified to add check
			int right  = min(cameraWidth  - 1, left + 1);
			int top    = min(cameraHeight - 1, (int)floor(v)); // Modified to add check
			int bottom = min(cameraHeight - 1, top  + 1);
			float uFrac = frac(u);
			float vFrac = frac(v);

			int baseIdx = cameraNum * cameraWidth * cameraHeight;
			int topRow    = baseIdx + top    * cameraWidth;
			int bottomRow = baseIdx + bottom * cameraWidth;
			uint topLeft     = cameraPixels[topRow    + left ];
			uint topRight    = cameraPixels[topRow    + right];
			uint bottomLeft  = cameraPixels[bottomRow + left ];
			uint bottomRight = cameraPixels[bottomRow + right];

			float r = lerp(lerp( topLeft  >> 16        ,  bottomLeft  >> 16        , vFrac),
				           lerp( topRight >> 16        ,  bottomRight >> 16        , vFrac), uFrac);
			float g = lerp(lerp((topLeft  >>  8) & 0xFF, (bottomLeft  >>  8) & 0xFF, vFrac),
					       lerp((topRight >>  8) & 0xFF, (bottomRight >>  8) & 0xFF, vFrac), uFrac);
			float b = lerp(lerp( topLeft         & 0xFF,  bottomLeft         & 0xFF, vFrac),
						   lerp( topRight        & 0xFF,  bottomRight        & 0xFF, vFrac), uFrac);

			totalColor += float4(r, g, b, 255.0f);
		}
	}

	totalColor /= ssaaFactor * ssaaFactor;
	result[(dtid.y * equirectangularWidth) + dtid.x] = ((int)totalColor.r << 16) | ((int)totalColor.g << 8) | (int)totalColor.b;
}

[numthreads(32,32,1)] // Must match threadsX, threadsY in CapturePanorama.cs
void CubeMapToEquirectangularPositiveY (uint3 dtid : SV_DispatchThreadID)
{
    static const int cameraNum = 2; /* PositiveY */
	static const float pi = 3.14159265f;
	float4 totalColor = float4(0.0f, 0.0f, 0.0f, 0.0f);

	int2 pos = int2(dtid.x, dtid.y + startY);
	int2 loopStart = pos * ssaaFactor;
	int2 loopEnd = loopStart + int2(ssaaFactor, ssaaFactor);

	for (int y = loopStart.y; y < loopEnd.y; y++)
	{
		for (int x = loopStart.x; x < loopEnd.x; x++)
		{
			float xcoord = (float)x / (equirectangularWidth * ssaaFactor);
			float ycoord = (float)y / (equirectangularHeight * ssaaFactor);
			float latitude = (ycoord - 0.5f) * pi;
			float longitude = (xcoord * 2.0f - 1.0f) * pi;

			float cosLat = cos(latitude);
			float equirectRayDirectionX = cosLat * sin (longitude);
			float equirectRayDirectionY = sin (latitude);
			float equirectRayDirectionZ = cosLat * cos (longitude);

			float distance = 1.0f / equirectRayDirectionY;
			float u = equirectRayDirectionX * distance, v = equirectRayDirectionZ * distance;

			u = (u + 1.0f) * 0.5f;
			v = (v + 1.0f) * 0.5f;
			
			// GetCameraPixelBilinear(cameraPixels, cameraNum, u, v);

			u *= cameraWidth;
			v *= cameraHeight;
			int left   = (int)floor(u);
			int right  = min(cameraWidth  - 1, left + 1);
			int top    = (int)floor(v);
			int bottom = min(cameraHeight - 1, top  + 1);
			float uFrac = frac(u);
			float vFrac = frac(v);

			int baseIdx = cameraNum * cameraWidth * cameraHeight;
			int topRow    = baseIdx + top    * cameraWidth;
			int bottomRow = baseIdx + bottom * cameraWidth;
			uint topLeft     = cameraPixels[topRow    + left ];
			uint topRight    = cameraPixels[topRow    + right];
			uint bottomLeft  = cameraPixels[bottomRow + left ];
			uint bottomRight = cameraPixels[bottomRow + right];

			float r = lerp(lerp( topLeft  >> 16        ,  bottomLeft  >> 16        , vFrac),
				           lerp( topRight >> 16        ,  bottomRight >> 16        , vFrac), uFrac);
			float g = lerp(lerp((topLeft  >>  8) & 0xFF, (bottomLeft  >>  8) & 0xFF, vFrac),
					       lerp((topRight >>  8) & 0xFF, (bottomRight >>  8) & 0xFF, vFrac), uFrac);
			float b = lerp(lerp( topLeft         & 0xFF,  bottomLeft         & 0xFF, vFrac),
						   lerp( topRight        & 0xFF,  bottomRight        & 0xFF, vFrac), uFrac);

			totalColor += float4(r, g, b, 255.0f);
		}
	}

	totalColor /= ssaaFactor * ssaaFactor;
	result[(dtid.y * equirectangularWidth) + dtid.x] = ((int)totalColor.r << 16) | ((int)totalColor.g << 8) | (int)totalColor.b;
}

[numthreads(32,32,1)] // Must match threadsX, threadsY in CapturePanorama.cs
void CubeMapToEquirectangularNegativeY (uint3 dtid : SV_DispatchThreadID)
{
    static const int cameraNum = 3; /* NegativeY */
	static const float pi = 3.14159265f;
	float4 totalColor = float4(0.0f, 0.0f, 0.0f, 0.0f);

	int2 pos = int2(dtid.x, dtid.y + startY);
	int2 loopStart = pos * ssaaFactor;
	int2 loopEnd = loopStart + int2(ssaaFactor, ssaaFactor);

	for (int y = loopStart.y; y < loopEnd.y; y++)
	{
		for (int x = loopStart.x; x < loopEnd.x; x++)
		{
			float xcoord = (float)x / (equirectangularWidth * ssaaFactor);
			float ycoord = (float)y / (equirectangularHeight * ssaaFactor);
			float latitude = (ycoord - 0.5f) * pi;
			float longitude = (xcoord * 2.0f - 1.0f) * pi;

			float cosLat = cos(latitude);
			float equirectRayDirectionX = cosLat * sin (longitude);
			float equirectRayDirectionY = sin (latitude);
			float equirectRayDirectionZ = cosLat * cos (longitude);

			float distance = 1.0f / equirectRayDirectionY;
			float u = equirectRayDirectionX * distance, v = equirectRayDirectionZ * distance;
			u = -u;

			u = (u + 1.0f) * 0.5f;
			v = (v + 1.0f) * 0.5f;
			
			// GetCameraPixelBilinear(cameraPixels, cameraNum, u, v);

			u *= cameraWidth;
			v *= cameraHeight;
			int left   = (int)floor(u);
			int right  = min(cameraWidth  - 1, left + 1);
			int top    = (int)floor(v);
			int bottom = min(cameraHeight - 1, top  + 1);
			float uFrac = frac(u);
			float vFrac = frac(v);

			int baseIdx = cameraNum * cameraWidth * cameraHeight;
			int topRow    = baseIdx + top    * cameraWidth;
			int bottomRow = baseIdx + bottom * cameraWidth;
			uint topLeft     = cameraPixels[topRow    + left ];
			uint topRight    = cameraPixels[topRow    + right];
			uint bottomLeft  = cameraPixels[bottomRow + left ];
			uint bottomRight = cameraPixels[bottomRow + right];

			float r = lerp(lerp( topLeft  >> 16        ,  bottomLeft  >> 16        , vFrac),
				           lerp( topRight >> 16        ,  bottomRight >> 16        , vFrac), uFrac);
			float g = lerp(lerp((topLeft  >>  8) & 0xFF, (bottomLeft  >>  8) & 0xFF, vFrac),
					       lerp((topRight >>  8) & 0xFF, (bottomRight >>  8) & 0xFF, vFrac), uFrac);
			float b = lerp(lerp( topLeft         & 0xFF,  bottomLeft         & 0xFF, vFrac),
						   lerp( topRight        & 0xFF,  bottomRight        & 0xFF, vFrac), uFrac);

			totalColor += float4(r, g, b, 255.0f);
		}
	}

	totalColor /= ssaaFactor * ssaaFactor;
	result[(dtid.y * equirectangularWidth) + dtid.x] = ((int)totalColor.r << 16) | ((int)totalColor.g << 8) | (int)totalColor.b;
}

#pragma kernel RenderStereo

RWStructuredBuffer<uint> result;
StructuredBuffer<uint> cameraPixels;
int equirectangularWidth;
int equirectangularHeight;
int ssaaFactor;
int cameraWidth;
int cameraHeight;
float tanHalfHFov, tanHalfVFov, hFovAdjust, vFovAdjust, interpupillaryDistance, circleRadius;
int numCirclePoints;

[numthreads(32,32,1)] // Must match threadsX, threadsY in CapturePanorama.cs
void RenderStereo (uint3 dtid : SV_DispatchThreadID)
{
	static const float pi = 3.14159265f;
    float xcoord = (float)dtid.x / equirectangularWidth;
    float ycoord = (float)dtid.y / equirectangularHeight;

    float latitude = (ycoord - 0.5f) * pi;
    float sinLat, cosLat;
	sincos(latitude, sinLat, cosLat);
    float longitude = (xcoord * 2.0f - 1.0f) * pi;
    float sinLong, cosLong;
	sincos(longitude, sinLong, cosLong);

    // Scale IPD down as latitude moves toward poles to avoid discontinuities
    float latitudeNormalized = latitude / (pi / 2.0f); // Map to [-1, 1]
    // Map from [-1, 1] to [0, 1] with curve 1 - x^2 that is smooth and symmetric at origin
    float ipdScale = 1.0f - latitudeNormalized * latitudeNormalized;
    float scaledEyeRadius = ipdScale * interpupillaryDistance / 2.0f;
    for (int i = 0; i < 2; i++)
    {
        // The following is equivalent to:
        // Quaternion eyesRotation = Quaternion.Euler(0.0f, longitude * 360.0f / (2 * pi), 0.0f);
        // float3 initialEyePosition = (i == 0 ? float3.left : float3.right) * scaledEyeRadius;
        // float3 pos = eyesRotation * initialEyePosition; // eye position
        // float3 dir = eyesRotation * float3.forward; // gaze direction

        float3 pos = float3(-cosLong * scaledEyeRadius, 0.0f, sinLong * scaledEyeRadius);
        if (i == 1) pos = -pos;
        float3 dir = float3(sinLong, 0.0f, cosLong);

        float eyeAngle = (i == 0 ? -pi / 2 : pi / 2) + longitude;
        float circlePointAngle = eyeAngle;
        if (ipdScale < 1.0f - 0.0001f) // Avoids some numerical issues
        {
            // Find place where gaze ray crosses circle (point on ray with magnitude equal to circleRadius)
            // (pos.x + dir.x * t)^2 + (pos.z + dir.z * t)^2 == circleRadius^2
            // Using unit magnitude of gazeDirection, positive solution is:
            float t = sqrt(circleRadius * circleRadius - dir.z * dir.z * pos.x * pos.x + 2 * dir.x * dir.z * pos.x * pos.z + (dir.z * dir.z - 1) * pos.z * pos.z) -
                        dir.x * pos.x - dir.z * pos.z;
            float3 circlePoint = pos + dir * t;
            circlePointAngle = atan2(circlePoint.x, circlePoint.z);
        }
        if (circlePointAngle < 0.0f) circlePointAngle += 2 * pi;
        if (circlePointAngle >= 2 * pi) circlePointAngle -= 2 * pi;

        float circlePointNumber = circlePointAngle / (2 * pi) * numCirclePoints;
        int circlePoint0 = (int)floor(circlePointNumber) % numCirclePoints;

        float4 color0 = float4(0, 0, 0, 0), color1 = float4(0, 0, 0, 0);
        for (int j=0; j < 2; j++)
        {
            int circlePointIdx = (j == 0 ? circlePoint0 : (circlePoint0 + 1) % numCirclePoints);
            float cameraPointAngle = 2 * pi * circlePointIdx / numCirclePoints;
            float sinCameraPointAngle, cosCameraPointAngle;
			sincos(cameraPointAngle, sinCameraPointAngle, cosCameraPointAngle);

            // Equivalent to (using fact that both dir and circlePointNorm are unit vectors):
            // Quaternion circlePointRotation = Quaternion.Euler(0.0f, cameraPointAngle * 360.0f / (2 * pi), 0.0f);
            // float3 circlePointNormal = circlePointRotation * float3.forward;
            // float newLongitudeDegrees = sign(cross(circlePointNormal, dir).y) * angle(circlePointNormal, dir);

            float newLongitude = sign(dir.x * cosCameraPointAngle - dir.z * sinCameraPointAngle) *
                                 acos(dir.z * cosCameraPointAngle + dir.x * sinCameraPointAngle);
            float sinNewLong, cosNewLong;
			sincos(newLongitude, sinNewLong, cosNewLong);

            // Select which of the two cameras for this point to use and adjust ray to make camera plane perpendicular to axes
            int cameraNumBase = circlePointIdx * 4;

            int cameraNum = cameraNumBase + (newLongitude >= 0.0f ? 1 : 0);
                        
            float longitudeAdjust = (newLongitude >= 0.0f ? -hFovAdjust : hFovAdjust);
            float longSum = newLongitude + longitudeAdjust;
			float sinLongSum, cosLongSum;
			sincos(longSum, sinLongSum, cosLongSum);

            // Equivalent to:
            // float3 textureRayDir = Quaternion.Euler(-latitude * 360.0f / (2 * pi), newLongitude * 360.0f / (2 * pi), 0.0f) * float3.forward;
            // float3 textureRayDirAdjusted = Quaternion.Euler(0.0f, longitudeAdjust * 360.0f / (2 * pi), 0.0f) * textureRayDir;
            float3 textureRayDirAdjusted = float3(cosLat * sinLongSum, sinLat, cosLat * cosLongSum);

            float u =  textureRayDirAdjusted.x / textureRayDirAdjusted.z / tanHalfHFov;
            float v = -textureRayDirAdjusted.y / textureRayDirAdjusted.z / tanHalfVFov;

            // There's a lot of vertical overlap so don't accept v near the edge of the left/right cameras, to avoid artifact pixels
            if (! (textureRayDirAdjusted.z > 0.0f && u * u <= 1.0f && v * v <= 1.0f - 0.1f) )
            {
                cameraNum = cameraNumBase + (latitude >= 0.0f ? 3 : 2);
                float latitudeAdjust = (latitude >= 0.0f ? vFovAdjust : -vFovAdjust);
                float sinLatAdjust, cosLatAdjust;
				sincos(latitudeAdjust, sinLatAdjust, cosLatAdjust);

                // Equivalent to:
                // textureRayDirAdjusted = Quaternion.Euler(latitudeAdjust * 360.0f / (2 * pi), 0.0f, 0.0f) * textureRayDir;
                textureRayDirAdjusted = float3(cosLat * sinNewLong,
                                               cosLatAdjust * sinLat - cosLat * cosNewLong * sinLatAdjust,
                                               sinLatAdjust * sinLat + cosLat * cosNewLong * cosLatAdjust);

                u =  textureRayDirAdjusted.x / textureRayDirAdjusted.z / tanHalfHFov;
                v = -textureRayDirAdjusted.y / textureRayDirAdjusted.z / tanHalfVFov;
            }

            u = (u + 1.0f) * 0.5f;
        	v = (v + 1.0f) * 0.5f;

			// GetCameraPixelBilinear(cameraPixels, cameraNum, u, v);

			u *= cameraWidth;
			v *= cameraHeight;
			int left   = (int)floor(u);
			int right  = min(cameraWidth  - 1, left + 1);
			int top    = (int)floor(v);
			int bottom = min(cameraHeight - 1, top  + 1);
			float uFrac = frac(u);
			float vFrac = frac(v);

			int baseIdx = cameraNum * cameraWidth * cameraHeight;
			int topRow    = baseIdx + top    * cameraWidth;
			int bottomRow = baseIdx + bottom * cameraWidth;
			uint topLeft     = cameraPixels[topRow    + left ];
			uint topRight    = cameraPixels[topRow    + right];
			uint bottomLeft  = cameraPixels[bottomRow + left ];
			uint bottomRight = cameraPixels[bottomRow + right];

			float r = lerp(lerp( topLeft  >> 16        ,  bottomLeft  >> 16        , vFrac),
				           lerp( topRight >> 16        ,  bottomRight >> 16        , vFrac), uFrac);
			float g = lerp(lerp((topLeft  >>  8) & 0xFF, (bottomLeft  >>  8) & 0xFF, vFrac),
					       lerp((topRight >>  8) & 0xFF, (bottomRight >>  8) & 0xFF, vFrac), uFrac);
			float b = lerp(lerp( topLeft         & 0xFF,  bottomLeft         & 0xFF, vFrac),
						   lerp( topRight        & 0xFF,  bottomRight        & 0xFF, vFrac), uFrac);

			float4 col = float4(r, g, b, 255.0f);
            if (j == 0) color0 = col; else color1 = col;
        }

        float4 c = lerp(color0, color1, frac(circlePointNumber));
        result[((dtid.y + equirectangularHeight * i) * equirectangularWidth) + dtid.x] =
		    ((int)c.r << 16) | ((int)c.g << 8) | (int)c.b;
    }
}
